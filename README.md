# ğŸ” Spark ETL Project: Bank Churn Analysis

This project implements an **ETL (Extract, Transform, Load)** pipeline using **Apache Spark (PySpark)** to process and transform a dataset of bank customers. The objective is to prepare clean data suitable for analysis of **customer churn**.

---

## ğŸ“ Project Structure

spark_etl_project/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ Bank_Churn.csv # Raw dataset
â”œâ”€â”€ output/
â”‚ â””â”€â”€ transformed_data.csv # Transformed output
â”œâ”€â”€ etl_spark.py # PySpark ETL script
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Git ignore file
â””â”€â”€ README.md # This file

## âš™ï¸ Features

- âœ… Built with **PySpark 4.0.0**
- âœ… Uses **Spark DataFrame API** for transformation
- âœ… Clean separation of raw and transformed data
- âœ… Output saved as `.csv`
- âœ… Ready for extension into Docker, Airflow, or AWS S3



## ğŸš€ How to Run

### 1. Clone the Repository

```bash
git clone https://github.com/Codewithkenny/spark_etl_project_Bank_Churn.git
cd spark_etl_project_Bank_Churn

ğŸ“¦ Requirements

    Python 3.8+

    Java 8 or 11 (for Spark)

    PySpark 4.0.0

Install all dependencies:

ğŸ“« Contact

Feel free to reach out:

Olapoju Agbomeji
GitHub: @Codewithkenny

ğŸ“ License

MIT License. See LICENSE for details.
